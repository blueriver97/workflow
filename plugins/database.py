from collections import OrderedDict
from enum import StrEnum

import hvac
import jaydebeapi
import pandas as pd
from pydantic import BaseModel, Field, SecretStr


class DatabaseType(StrEnum):
    """
    Enum for supported database types.
    """

    MYSQL = "mysql"
    SQLSERVER = "sqlserver"


class VaultSettings(BaseModel):
    url: str = Field(description="Vault URL")
    username: str = Field(description="Vault username")
    password: SecretStr = Field(description="Vault password")
    secret_path: str = Field(description="Vault secret path")


class DatabaseSettings(BaseModel):
    type: str = Field(description="Database type (mysql, sqlserver)")
    host: str = Field(default="", description="Database host address")
    port: int = Field(default=3306, description="Database port number")
    user: str = Field(default="", description="Database username")
    password: SecretStr = Field(default=SecretStr(""), description="Database password")


def get_vault(config: VaultSettings):
    url = config.url
    username = config.username
    password = config.password.get_secret_value()
    secret_path = config.secret_path

    if not all([url, username, password, secret_path]):
        raise ValueError("from env: url, username, password, secret_path must be set")

    try:
        client = hvac.Client(url=url)
        client.auth.userpass.login(username=username, password=password)
        response = client.read(path=secret_path)

        if not isinstance(response, dict) or "data" not in response or "data" not in response["data"]:
            raise ValueError(f"Could not find data at Vault path: '{secret_path}'")

        secret = response["data"]["data"]
        return {
            "host": secret.get("host"),
            "port": int(secret.get("port", 0)),
            "user": secret.get("user"),
            "password": secret.get("password"),
        }
    except Exception as e:
        print(f"An error occurred during Vault initialization: {e}")
        return {}


def get_jdbc_options(config: DatabaseSettings, database: str | None = None) -> dict[str, str]:
    """Generates JDBC connection options based on the database type in settings."""
    options: dict[str, str] = {}

    if config.type == DatabaseType.MYSQL:
        db_name = database if database else ""
        options["url"] = f"jdbc:mysql://{config.host}:{config.port}/{db_name}?zeroDateTimeBehavior=convertToNull"
        options["driver"] = "com.mysql.cj.jdbc.Driver"

    elif config.type == DatabaseType.SQLSERVER:
        db_prop = f";databaseName={database}" if database else ""
        options["url"] = f"jdbc:sqlserver://{config.host}:{config.port}{db_prop};encrypt=false;"
        options["driver"] = "com.microsoft.sqlserver.jdbc.SQLServerDriver"

    else:
        raise ValueError(f"Unsupported database type: {config.type}")

    if config.user:
        options["user"] = config.user

    if config.password:
        options["password"] = config.password.get_secret_value()

    return options


def create_jdbc_connection(
    options: dict[str, str],
    jar_path: str,
):
    """
    Creates a JDBC connection using jaydebeapi.

    Args:
        options: JDBC options generated by get_jdbc_options
        jar_path: Path to the JDBC driver JAR file

    Returns:
        jaydebeapi.Connection
    """

    driver = options["driver"]
    url = options["url"]

    user = options.get("user")
    password = options.get("password")

    credentials: list[str] | None = None
    if user and password:
        credentials = [user, password]

    conn = jaydebeapi.connect(
        driver,
        url,
        credentials,
        jar_path,
    )

    return conn


def get_primary_keys(
    config: DatabaseSettings,
    database: str,
    tables: list[str],
    jar_path: str,
) -> dict[str, list[str]]:
    """
    Retrieves primary key information for the specified tables using pandas.

    Args:
        config: Database settings
        database: Database name
        tables: List of fully qualified table names
        jar_path: JDBC driver jar path

    Returns:
        { "schema.table": ["col1", "col2"] }
    """

    if not tables:
        return {}

    options = get_jdbc_options(config, database)
    conn = create_jdbc_connection(options, jar_path)

    try:
        placeholders = ",".join(["?"] * len(tables))

        if config.type == DatabaseType.MYSQL:
            query = f"""
                SELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, SEQ_IN_INDEX
                FROM information_schema.STATISTICS
                WHERE CONCAT_WS('.', TABLE_SCHEMA, TABLE_NAME) IN ({placeholders})
                  AND INDEX_NAME = 'PRIMARY'
                ORDER BY TABLE_SCHEMA, TABLE_NAME, SEQ_IN_INDEX
            """

        elif config.type == DatabaseType.SQLSERVER:
            query = f"""
                SELECT
                    t.TABLE_CATALOG AS TABLE_SCHEMA,
                    t.TABLE_NAME,
                    c.COLUMN_NAME,
                    c.ORDINAL_POSITION
                FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS t
                JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE c
                  ON c.CONSTRAINT_NAME = t.CONSTRAINT_NAME
                WHERE t.CONSTRAINT_TYPE = 'PRIMARY KEY'
                  AND CONCAT(t.TABLE_CATALOG, '.dbo.', t.TABLE_NAME) IN ({placeholders})
            """

        else:
            raise ValueError(f"Unsupported database type: {config.type}")

        # pandas 기반 조회
        df = pd.read_sql_query(query, conn, params=tuple(tables))

        result: dict[str, list[str]] = {}

        for _, row in df.iterrows():
            key = f"{row['TABLE_SCHEMA']}.{row['TABLE_NAME']}"
            result.setdefault(key, []).append(row["COLUMN_NAME"])

        return result

    finally:
        conn.close()


def get_table_schema_info(
    config: DatabaseSettings,
    tables: list[str],
    jar_path: str,
) -> dict[str, dict[str, str]]:
    """
    Retrieves column schema information for the specified tables.

    Args:
        config: Database settings
        tables: Fully qualified table names
        jar_path: JDBC driver jar path

    Returns:
        {
            "schema.table": {
                "col1": "varchar(20)",
                "col2": "int"
            }
        }
    """

    if not tables:
        return {}

    database = tables[0].split(".")[0]
    options = get_jdbc_options(config, database)
    conn = create_jdbc_connection(options, jar_path)

    try:
        placeholders = ",".join(["?"] * len(tables))

        if config.type == DatabaseType.MYSQL:
            query = f"""
                SELECT
                    TABLE_SCHEMA,
                    TABLE_NAME,
                    COLUMN_NAME,
                    COLUMN_TYPE,
                    ORDINAL_POSITION
                FROM information_schema.COLUMNS
                WHERE CONCAT_WS('.', TABLE_SCHEMA, TABLE_NAME) IN ({placeholders})
                ORDER BY TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION
            """

        elif config.type == DatabaseType.SQLSERVER:
            query = f"""
                SELECT
                    TABLE_CATALOG AS TABLE_SCHEMA,
                    TABLE_NAME,
                    COLUMN_NAME,
                    DATA_TYPE AS COLUMN_TYPE,
                    ORDINAL_POSITION
                FROM INFORMATION_SCHEMA.COLUMNS
                WHERE CONCAT(TABLE_CATALOG, '.dbo.', TABLE_NAME) IN ({placeholders})
                ORDER BY TABLE_CATALOG, TABLE_NAME, ORDINAL_POSITION
            """

        else:
            raise ValueError(f"Unsupported database type: {config.type}")

        df = pd.read_sql_query(query, conn, params=tuple(tables))

        if df.empty:
            return {}

        # 정렬 보장
        df = df.sort_values(["TABLE_SCHEMA", "TABLE_NAME", "ORDINAL_POSITION"])

        result: dict[str, dict[str, str]] = {}

        for (schema, table), group in df.groupby(["TABLE_SCHEMA", "TABLE_NAME"]):
            ordered_columns = OrderedDict(zip(group["COLUMN_NAME"], group["COLUMN_TYPE"]))

            if config.type == DatabaseType.SQLSERVER:
                key = f"{schema}.dbo.{table}"
            else:
                key = f"{schema}.{table}"

            result[key] = ordered_columns

        return result

    finally:
        conn.close()


def get_partition_key_info(
    config: DatabaseSettings,
    tables: list[str],
    jar_path: str,
) -> dict[str, str]:
    """
    Retrieves partition key column for the specified tables.

    Returns:
        {
            "schema.table": "column_name"
        }
    """

    if not tables:
        return {}

    database = tables[0].split(".")[0]
    options = get_jdbc_options(config, database)
    conn = create_jdbc_connection(options, jar_path)

    try:
        placeholders = ",".join(["?"] * len(tables))

        if config.type == DatabaseType.MYSQL:
            query = f"""
                SELECT
                    c.TABLE_SCHEMA,
                    c.TABLE_NAME,
                    c.COLUMN_NAME
                FROM INFORMATION_SCHEMA.COLUMNS AS c
                JOIN (
                    SELECT
                        TABLE_SCHEMA,
                        TABLE_NAME,
                        MIN(ORDINAL_POSITION) AS min_ordinal,
                        MIN(
                            CASE
                                WHEN EXTRA = 'auto_increment'
                                THEN ORDINAL_POSITION
                                ELSE NULL
                            END
                        ) AS extra_ordinal
                    FROM INFORMATION_SCHEMA.COLUMNS
                    WHERE CONCAT_WS('.', TABLE_SCHEMA, TABLE_NAME) IN ({placeholders})
                      AND (
                            DATA_TYPE IN ('int', 'bigint', 'date', 'datetime', 'timestamp')
                            OR EXTRA LIKE 'auto_increment'
                          )
                    GROUP BY TABLE_SCHEMA, TABLE_NAME
                ) AS t
                  ON c.TABLE_SCHEMA = t.TABLE_SCHEMA
                 AND c.TABLE_NAME = t.TABLE_NAME
                 AND c.ORDINAL_POSITION = COALESCE(t.extra_ordinal, t.min_ordinal)
                ORDER BY c.TABLE_SCHEMA, c.TABLE_NAME, c.ORDINAL_POSITION
            """

        elif config.type == DatabaseType.SQLSERVER:
            query = f"""
                SELECT
                    DB_NAME() AS TABLE_SCHEMA,
                    c.TABLE_NAME,
                    c.COLUMN_NAME
                FROM INFORMATION_SCHEMA.COLUMNS AS c
                JOIN (
                    SELECT
                        TABLE_SCHEMA,
                        TABLE_NAME,
                        MIN(ORDINAL_POSITION) AS min_ordinal,
                        MIN(
                            CASE
                                WHEN COLUMNPROPERTY(
                                        OBJECT_ID(CONCAT(TABLE_SCHEMA, '.', TABLE_NAME)),
                                        COLUMN_NAME,
                                        'IsIdentity'
                                     ) = 1
                                THEN ORDINAL_POSITION
                            END
                        ) AS extra_ordinal
                    FROM INFORMATION_SCHEMA.COLUMNS
                    WHERE (
                            DATA_TYPE IN ('date', 'datetime', 'datetime2', 'timestamp')
                            OR COLUMNPROPERTY(
                                   OBJECT_ID(CONCAT(TABLE_SCHEMA, '.', TABLE_NAME)),
                                   COLUMN_NAME,
                                   'IsIdentity'
                               ) = 1
                          )
                      AND CONCAT(DB_NAME(), '.', TABLE_SCHEMA, '.', TABLE_NAME)
                          IN ({placeholders})
                    GROUP BY TABLE_SCHEMA, TABLE_NAME
                ) AS t
                  ON c.TABLE_SCHEMA = t.TABLE_SCHEMA
                 AND c.TABLE_NAME = t.TABLE_NAME
                 AND c.ORDINAL_POSITION = COALESCE(t.extra_ordinal, t.min_ordinal)
                ORDER BY TABLE_SCHEMA, c.TABLE_NAME, c.ORDINAL_POSITION
            """

        else:
            raise ValueError(f"Unsupported database type: {config.type}")

        df = pd.read_sql_query(query, conn, params=tuple(tables))

        if df.empty:
            return {}

        # 테이블별 첫 컬럼만 선택 (이미 1 row 보장되지만 안전 처리)
        result: dict[str, str] = {}

        for _, row in df.iterrows():
            if config.type == DatabaseType.SQLSERVER:
                key = f"{row['TABLE_SCHEMA']}.dbo.{row['TABLE_NAME']}"
            else:
                key = f"{row['TABLE_SCHEMA']}.{row['TABLE_NAME']}"

            result[key] = row["COLUMN_NAME"]

        return result

    finally:
        conn.close()
