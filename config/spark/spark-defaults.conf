#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

# ==================== 이벤트 로그 설정 ====================
# Spark 애플리케이션 실행 이벤트를 로그로 기록하여 히스토리 서버에서 완료된 작업 정보를 확인할 수 있게 함
# 효과: 디버깅 및 성능 분석, 작업 실행 이력 추적 가능
spark.eventLog.enabled                          true

# 이벤트 로그가 저장될 S3 경로
# 효과: 히스토리 서버가 이 경로에서 로그를 읽어 UI에 표시
spark.eventLog.dir                              $S3_BUCKET/spark/logs

# ==================== YARN 관련 설정 ====================
# YARN 작업 제출 시 임시 파일이 저장되는 스테이징 디렉토리
# 효과: 로컬 디스크 대신 S3를 사용하여 분산 환경에서 안정적인 파일 접근 가능
spark.yarn.stagingDir                           $S3_BUCKET/spark/staging

# Spark 라이브러리 jar 파일들을 압축한 아카이브 경로
# 효과: 각 노드에 jar를 개별 전송하지 않고 아카이브를 전송하여 네트워크 오버헤드 감소 및 애플리케이션 시작 시간 단축
spark.yarn.archive                              $S3_BUCKET/spark/jars/spark-libs.tar.gz

# 히스토리 서버의 주소 (YARN ResourceManager가 참조)
# 효과: YARN UI에서 완료된 Spark 애플리케이션 링크가 히스토리 서버로 연결됨
spark.yarn.historyServer.address                admin:18080

# PySpark 가상환경 아카이브를 Executor에 배포
# 효과: Python 의존성 패키지를 모든 Executor 노드에 일관되게 배포하여 환경 불일치 문제 방지
spark.yarn.dist.archives                        $S3_BUCKET/spark/venv/pyspark_venv_$ARCH.tar.gz#environment

# ==================== 히스토리 서버 설정 ====================
# 히스토리 서버가 이벤트 로그를 읽어올 디렉토리
# 효과: 완료된 애플리케이션의 실행 정보를 웹 UI에서 조회 가능
spark.history.fs.logDirectory                   $S3_BUCKET/spark/logs

# 히스토리 서버의 웹 UI 포트
# 효과: http://admin:18080 으로 히스토리 서버 접속
spark.history.ui.port                           18080

# 히스토리 서버의 오래된 로그 자동 삭제 기능 활성화
# 효과: 스토리지 공간 절약 및 불필요한 오래된 로그 파일 관리
spark.history.fs.cleaner.enabled                true

# 로그 보관 기간 (7일)
# 효과: 7일이 지난 이벤트 로그 파일은 자동으로 삭제되어 스토리지 비용 절감
spark.history.fs.cleaner.maxAge                 7d

# ==================== Shuffle 서비스 설정 ====================
# Dynamic Allocation 활성화
# 효과: Spark가 상황에 맞춰 알아서 Executor 수를 조절하는 기능
spark.dynamicAllocation.enabled                 false
# spark.dynamicAllocation.minExecutors 최소한 유지할 Executor 개수 (하한선)
# spark.dynamicAllocation.maxExecutors 최대로 늘릴 수 있는 Executor 개수 (상한선)
# spark.dynamicAllocation.initialExecutors 앱 시작 시 처음에 띄울 개수
# spark.dynamicAllocation.executorAllocationRatio 자원을 요청할 때 얼마나 공격적으로 요청할지 비율 (예: 1이면 필요한 만큼 다 요청, 0.5면 절반만 요청)

# External Shuffle Service 활성화
# 효과: Executor가 종료되어도 shuffle 데이터가 유지되어 동적 할당(Dynamic Allocation) 사용 시 안정성 향상
spark.shuffle.service.enabled                   true

# Shuffle 서비스가 사용할 포트
# 효과: NodeManager의 Auxiliary Service로 동작하는 Shuffle Service와 통신
spark.shuffle.service.port                      7337

# Executor 종료 시 shuffle 데이터도 함께 제거
# 효과: 스토리지 공간 확보 (단, Dynamic Allocation 사용 시에는 false로 변경 필요)
spark.shuffle.service.removeShuffle             true

# scratch 공간에 사용할 디렉터리, 맵 출력 파일 및 디스크에 저장되는 RDD를 포함합니다.
# 이는 시스템의 빠른 로컬 디스크에 있어야 합니다. 또한 여러 디스크에 있는 여러 디렉터리의 쉼표로 구분된 목록일 수도 있습니다.
# 참고: 이는 클러스터 매니저가 설정한 환경 변수인 SPARK_LOCAL_DIRS(Standalone) 또는 LOCAL_DIRS(YARN)에 의해 덮어씌워집니다.
spark.local.dir                                 /tmp

# ==================== Driver 리소스 설정 ====================
# Driver에 할당할 CPU 코어 수
# 효과: Driver의 병렬 처리 능력 결정, 너무 많이 할당하면 클러스터 리소스 낭비
spark.driver.cores                              1

# Driver에 할당할 메모리
# 효과: Driver는 작업 조정 및 결과 수집을 담당하므로 충분한 메모리 필요 (collect 등 사용 시 주의)
spark.driver.memory                             2g

# Driver JVM의 추가 Java 옵션
# 효과: G1GC 사용으로 GC 성능 향상, OOM 발생 시 힙 덤프 생성으로 문제 분석 가능
spark.driver.extraJavaOptions                   -XX:+UseG1GC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/yarn

# ==================== Executor 리소스 설정 ====================
# Executor당 할당할 CPU 코어 수
# 효과: 각 Executor가 동시에 실행할 수 있는 태스크 수 결정 (일반적으로 Task 수 = Cores 수)
spark.executor.cores                            2

# Executor당 할당할 메모리
# 효과: 데이터 처리를 위한 메모리 공간, 부족하면 OOM 에러 발생
spark.executor.memory                           2g

# Executor JVM의 추가 Java 옵션
# 효과: G1GC 사용으로 GC 성능 향상, OOM 발생 시 힙 덤프 생성으로 문제 분석 가능
spark.executor.extraJavaOptions                 -XX:+UseG1GC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/yarn

# Executor 로그 롤링 설정: 최대 보관 파일 수
# 효과: 로그 파일이 너무 많이 쌓이는 것을 방지하여 디스크 공간 관리
spark.executor.logs.rolling.maxRetainedFiles    5

# Executor 로그 롤링 전략 (시간 기반)
# 효과: 로그를 시간 단위로 분할하여 관리 용이
spark.executor.logs.rolling.strategy            time

# 로그 롤링 주기 (매일)
# 효과: 매일 새로운 로그 파일을 생성하여 날짜별 로그 추적 가능
spark.executor.logs.rolling.time.interval       daily

# ==================== 메모리 관리 설정 ====================
# 캐싱 및 내부 메타데이터 저장에 사용할 메모리 비율 (기본값 0.5)
# 효과: 0.2로 낮춰서 실행(Execution) 메모리를 더 많이 확보, shuffle/join 연산이 많은 워크로드에 유리
spark.memory.storageFraction                    0.2

# 직렬화 방식 설정 (Kryo 사용)
# 효과: Java 기본 직렬화보다 빠르고 압축률이 높아 네트워크 전송 및 디스크 I/O 성능 향상
spark.serializer                                org.apache.spark.serializer.KryoSerializer

# ==================== 클래스패스 우선순위 설정 ====================
# 사용자 jar 파일을 시스템 클래스패스보다 먼저 로드
# 효과: 라이브러리 버전 충돌 시 사용자가 지정한 버전 우선 사용, 의존성 충돌 문제 해결
spark.driver.userClassPathFirst                 true
spark.executor.userClassPathFirst               true

# ==================== 네트워킹 포트 설정 ====================
# Spark Driver & Executor Port 설정
# 효과: 방화벽 규칙 설정 시 예측 가능한 포트 범위 사용, 보안 그룹 설정 간소화
# 참고: https://spark.apache.org/docs/latest/security.html#all-cluster-managers
# 참고: https://spark.apache.org/docs/latest/configuration.html#networking

# Block Manager가 사용할 포트 (블록 데이터 전송)
# 효과: Executor 간 데이터 셔플 시 사용, 고정 포트로 방화벽 규칙 설정 용이
spark.blockManager.port                         40000

# Driver가 사용할 포트 (Executor와의 통신)
# 효과: Driver-Executor 간 제어 메시지 전송, 고정 포트로 네트워크 설정 단순화
spark.driver.port                               40050

# 포트 충돌 시 재시도 횟수
# 효과: 지정된 포트가 사용 중이면 다음 포트를 시도 (예: 40000, 40001, ... 40050까지)
spark.port.maxRetries                           50

# ==================== Prometheus 메트릭 수집 설정 ====================
# Spark UI에서 Prometheus 포맷의 메트릭 노출
# 효과: 별도의 JMX Exporter 없이 Spark 메트릭을 Prometheus로 수집 가능, 모니터링 인프라 구축 간소화
spark.ui.prometheus.enabled                     true

# Structured Streaming 메트릭 수집 활성화
# 효과: 스트리밍 작업의 처리량, 지연시간 등 메트릭 추적 가능
spark.sql.streaming.metricsEnabled              true

# Executor의 상세 메트릭 수집 (JVM, GC 등)
# 효과: Executor의 리소스 사용량 및 성능 지표 모니터링, 성능 최적화에 활용
spark.metrics.executorMetricsSource.enabled     true

# 프로세스 트리 메트릭 비활성화
# 효과: 불필요한 메트릭 수집 오버헤드 감소 (일반적으로 필요하지 않음)
spark.executor.processTreeMetrics.enabled       false

# 정적 소스 메트릭 비활성화
# 효과: 불필요한 메트릭 수집 오버헤드 감소
spark.metrics.staticSources.enabled             false
